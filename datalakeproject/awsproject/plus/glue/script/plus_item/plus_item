#Incremental Load

import sys
from awsglue.transforms import *
from awsglue.utils import getResolvedOptions
from pyspark.context import SparkContext
from awsglue.context import GlueContext
from awsglue.job import Job
from foundationutil import *

## @params: [JOB_NAME]
args = getResolvedOptions(sys.argv, ['JOB_NAME'])

sc = SparkContext()
glueContext = GlueContext(sc)
spark = glueContext.spark_session
job = Job(glueContext)
job.init(args['JOB_NAME'], args)

#Pass Job Name
job_name=args['JOB_NAME']

# specify source table name  and target table name
# source json schema name : item.json
source_tbl='item'
target_tbl='plus_item'

partitionKeys=['chain_id']

#Specify the data will get load loaded in which folder in target bucket
target_prefix='//plus//fmw'
source_prefix='//plus//fmw'


# specify primary key and foreign key columns name
map_keyval = {'plus_item_key':['sku_id'],
           'plus_merch_class_key':['chain_id','class_id'],
           'plus_merch_department_key':['chain_id','dept_id']
		    }	

#Build foundation frame  to get existing data into  foundation frame
fdn_hash_df=read_fdn(target_prefix,target_tbl,spark)

#  Clean source  df 
inc_clean_df=clean_sourcedf(source_prefix,source_tbl,spark)

#Add Hash value to incremental df
inc_hash_df=calc_rowhash(inc_clean_df)

# Compare incremental df to foundation to df for  capturing incremental records 
inc_leftjoined_fdn_df=inc_leftjoin_fdn(fdn_hash_df,inc_hash_df)

# Call base frame with incremental frame
base_sdf=create_base_frame(inc_leftjoined_fdn_df
                            ,map_keyval
                            ,glueContext
                            ,spark
                            ,job_name
                            ,source_tbl
                            ,audit_cols=['foundation_program_nam','foundation_insert_tms'])
        
# so pass base_sdf ot target_sdf based on the previous to this write function
status=write_to_sink(base_sdf,target_tbl,partitionKeys,glueContext,target_prefix)


#moving to archive
move_to_archive(status,source_prefix,source_tbl)

job.commit()