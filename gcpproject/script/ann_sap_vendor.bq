#!/usr/bin/bash
. ${HOME}/lib/set_env.sh
. ${HOME}/lib/common.sh

#Creating table in landing dataset
bq load --replace=true --source_format=CSV --quote='' --field_delimiter="|" \
        --schema=${schema_path}/edl_landing/ann_sap_vendor.json \
        edl_landing.ann_sap_vendor \
        "gs://${default_bucket}/pre/sapwm/ANN_SAP_VENDOR_*.dat"
rc_check $? "Load edl_landing"

#Loading edl_stage table from edl_landing dataset
#Loading all batch_ids from GCP Bucket
bq query  --max_rows 1 --allow_large_results --destination_table edl_stage.ann_sap_vendor_new --use_legacy_sql=false <<!
SELECT
 #parse_DATE("%Y%m%d",date_time) as date_time,
  parse_timestamp("%Y%m%d %H%M%S",date_time,"America/New_York") as date_time,
  vendor_number,
  vendor_name,
  batch_id
FROM edl_landing.ann_sap_vendor
where vendor_number is not null
!

rc_check $? "Load incremental data from edl_landing into temp table"


##MERGE or UPSERT new edl_stage table from existing table
bq query --max_rows 1 --allow_large_results --append_table --destination_table edl_stage.ann_sap_vendor_new --use_legacy_sql=false <<!
SELECT c.*
FROM edl_stage.pre_sap_vendor c
WHERE c.batch_id NOT IN (
  SELECT
    w.batch_id
  FROM
    edl_stage.ann_sap_vendor_new w
    group by w.batch_id
)
!
rc_check $? "append legacy records into the temp table"


##cleansing and archival
bq cp --force edl_stage.pre_sap_vendor edl_archive.pre_sap_vendor
rc_check $? "archive copy"
bq cp --force edl_stage.ann_sap_vendor_new edl_stage.pre_sap_vendor
rc_check $? "replace the staging table with the new table"
bq rm --force edl_stage.ann_sap_vendor_new
rc_check $? "drop the deduped temp table"

##archiving bucket files
archive_bucket_files "gs://${default_bucket}/pre/sapwm/ANN_SAP_VENDOR_*.dat"
rc_check $? "archive bucket files"

